---
title: "Pedagogy Exam"
author: "Anna Wolford, Aaron Oustrich, Josh Bergstrom"
format: pdf
editor: visual
---

```{r messages=FALSE, echo=FALSE}
library(vroom)
library(tidyverse)
library(corrplot)
library(MASS)
library(nlme)
source("predictgls.R")
```

```{r message=FALSE}
ped <- vroom("ClassAssessment.txt")
ped$Semester <- as.factor(ped$Semester)
```

```{r}
summary(ped)

# ped |> 
#   ggplot(aes(y = Final)) +
#   geom_boxplot(aes(x = Exam1)) +
#   geom_boxplot(aes(x = Exam2)) +
#   geom_boxplot(aes(x = Exam3))

ped |> 
  ggplot(aes(y = Final)) +
  geom_boxplot(aes(x = Semester))

## It appeared that as Exam 3 avg scores increased, avg Final Grades increased
 
ped |> 
  ggplot(aes(y = Final)) +
  geom_point(aes(x = Exam3, color = Semester))
ped |> 
  ggplot(aes(y = Final)) +
  geom_point(aes(x = Exam2, color = Semester))
ped |> 
  ggplot(aes(y = Final)) +
  geom_point(aes(x = Exam1, color = Semester))
```

# Basic lm model
```{r}
ped.lm <- lm(Final ~ .  , data = ped)
summary(ped.lm)

```

```{r message=FALSE}
ped |> 
  ggplot(aes(y = MASS::stdres(ped.lm),
             x = ped.lm$fitted.values)) +
  geom_point() +
  geom_smooth(se = F) +
  labs(x = "Fitted Values",
       y = "Standardized Residuals")
```

```{r}
lmtest::bptest(ped.lm)
```

# GLS model
```{r}

ped.gls <- gls(model=Final~. ,
    data=ped,
    weights=varFixed(~1/NStudents),
    method="ML")

summary(ped.gls)
```

# GLS assumptions

### Linearity

```{r}
car::avPlots(ped.lm)
```

The only added-variable plot between Income and EatingOut appears linear. This assumption is met.

### Independence

It's likely safe to assume that the 523 households from this survey were randomly selected, but since it doesn't specify that they were, we must examine the data more deeply. Since the average weekly expenditure on ped not cooked at home for a family does not usually depend on the average weekly expenditure on ped not cooked at home of another family, we can assume these responses are independent. This assumption is met.

### Normality

```{r message=FALSE}
ggplot(data = data.frame(residual = resid(ped.gls, type="pearson")),
       aes(x = residual)) +
  geom_histogram(binwidth = 0.2) +
  labs(title = "Histogram of Standardized Residuals",
       x = "Standardized Residuals",
       y = "Frequency")
```

```{r warning=FALSE}
ks.test(resid(ped.gls, type="pearson"), "pnorm")
```

The KS-test outputs a large p-value (meaning we have insufficient evidence to say anything except that residuals are normally distributed), and the histogram looks approximately normal. This assumption is met.

### Equal Variance

```{r message=FALSE}
ggplot(data = data.frame(residual = resid(ped.gls, type="pearson")),
       aes(x = residual,
           y = ped.gls$fitted)) +
  geom_point() +
  geom_smooth(se = F) +
  labs(y = "Standardized Residuals",
       x = "Fitted Values")
```

```{r}
lmtest::bptest((resid(ped.gls, type="pearson"))^2 ~ fitted(ped.gls))
```

The BP-test outputs a large p-value, and the scatter plot of fitted v. standardized residuals appears to have constant variance. This assumption is now met.

# Cross Validation 

## Leave One Out
```{r}
n <- nrow(ped)
rpmse <- rep(x=NA, times=n)
wid <- rep(x=NA, times=n)
bias <- rep(x=NA, times=n)
cvg <- rep(x=NA, times=n)
my.preds.df <- data.frame()


for(i in 1:n){
  ## Select test observations

  
  ## Split into test and training sets
  test.set <- ped[i,]
  train.set <- ped[-i,]
  
  ## Fit a lm() using the training data
  train.gls <- gls(model=Final~. ,
    data=train.set,
    weights=varFixed(~1/NStudents),
    method="ML")
  
  ## Generate predictions for the test set
  my.preds <- predictgls(train.gls, newdframe=test.set, level = .95)
  my.preds.df <- rbind(my.preds.df, my.preds)
  
   
  ## Calculate RPMSE
  rpmse[i] <- (test.set[['Final']]-my.preds[,'Prediction'])^2 %>% mean() %>% sqrt()
  
  
  ## Calculate Width - width of the interval
  wid[i] <- (my.preds[,'upr'] - my.preds[,'lwr']) %>% mean()
  
  
  ## Bias
  bias[i] <- mean(my.preds[,'Prediction']-test.set[['Final']])
  
  ## Calculate Coverage - num of datapoints within interval (mean)
  cvg[i] <- ((test.set[['Final']] > my.preds[,'lwr']) & (test.set[['Final']] < my.preds[,'upr'])) %>% mean()
  
}
```

## CV Results
```{r}
# RPMSE
hist(rpmse, main="RPMSE Histogram", xlab="RPMSE")
mean(rpmse) #rpmse is how off you are on average 

#standard deviation of pedary = 10996.17
mean(cvg)
mean(bias)

## use for q 3
(var(ped$Final) - mean(rpmse)^2 ) / var(ped$Final)  # 89.5% of overall variance reduction
# with semester, 79%

## can we use R^2? nooooo
# num <- sum((ped$Final - my.preds.df$Prediction)^2)
# denom <-  sum((ped$Final - mean(ped$Final))^2)
# 1-num/denom

cor(my.preds.df$Prediction, ped$Final) ## use for q3 
# with semester included: 86.9%

# Width histogram
hist(wid, main="Width Histogram", xlab="Width")
mean(wid)
```

## CV Prediction Plots
```{r}
dataPreds <- predictgls(glsobj=ped.gls, level=0.95, newdframe=ped)
ggplot() + 
  geom_point(data=dataPreds, 
             mapping=aes(x=Exam3, y=Final)) + #Scatterplot
  geom_line(data=dataPreds, 
            mapping=aes(x=Exam3, y=Prediction)) + #Prediction Line
  geom_line(data=dataPreds, 
            mapping=aes(x=Exam3, y=lwr), 
            color="red", linetype="dashed") + #lwr bound
  geom_line(data=dataPreds, 
            mapping=aes(x=Exam3, y=upr), 
            color="red", linetype="dashed") #Upper bound

ggplot() +
  geom_point(data=dataPreds,
             mapping=aes(x=Exam2, y=Final)) + #Scatterplot
  geom_line(data=dataPreds,
            mapping=aes(x=Exam2, y=Prediction)) + #Prediction Line
  geom_line(data=dataPreds,
            mapping=aes(x=Exam2, y=lwr),
            color="red", linetype="dashed") + #lwr bound
  geom_line(data=dataPreds,
            mapping=aes(x=Exam2, y=upr),
            color="red", linetype="dashed") #Upper bound
```

# Hypothesis Testing and Confidence Intervals under Heteroskedasticity

# RESEARCH Q 1: Effect of activites? Everything is significant except for Quiz

```{r}
coef(ped.gls)
summary(ped.gls)
summary(ped.gls)$tTable # t table
summary(ped.gls)$sigma # estimate of s
# coef(ped.gls$modelStruct, unconstrained=FALSE)


```

IT appears that the significant factors are Exam 3 and Exam 2.

*Carry out a hypothesis test that beta_Quiz=0 . Carry out a hypothesis test that beta_HW=0 Report the p -value and draw an appropriate conclusion.*

```{r}
a <- matrix(c(0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1), nrow=1)
summary(multcomp::glht(ped.gls, linfct=a, rhs=0))

hw <- matrix(c(0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0), nrow=1)
summary(multcomp::glht(ped.gls, linfct=hw, rhs=0))
```

Because of a nonsignificant p value, we fail to reject the null that Beta_Quiz = 0. Therefore Quiz does not have a significant effect in our model.

Construct a 95% confidence interval for beta_Exam3 and beta_Exam2.

```{r}
confint(ped.gls, level = 0.95)
confint(ped.gls, level = 0.95)[13,] ## Exam 2
confint(ped.gls, level = 0.95)[14,] ## Exam 3
```

## RESEARCH Q NUM 4:

Historically, were there any semesters that had either better or worse student learning than average? Were there any semesters that were significantly different than another semester?

Does semester1=semester2=....=semester10? Hypothesis test...

```{r}
final_avg <- mean(ped$Final)

ped %>%
  group_by(Semester) %>%
  summarize("SemesterAvg"=mean(Final), "Difference"=final_avg-SemesterAvg)



```

```{r}
semester <- matrix(c(0,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0), nrow=1)
summary(multcomp::glht(ped.gls, linfct=semester, rhs=0))
```

WIth a p value of 0.426 fail to reject there is a statistically significant semester... blah
